---
title: "(Very) basic steps on how to weight a survey sample"
subtitle: "An explained example with R code"
author: "JosepER"
output: html_notebook
---

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(foreign)
library(magrittr)
library(tidyverse)
options(scipen = 9999)
```


## Introduction

### Note and bibliography 

This is a short guide that shows to weight a survey. Please keep in mind that
there are many different ways of weighting a survey. This guide intends to be a practical document and
intentionally avoids explaining complex or advanced methods. Instead, I aim at providing 
a way of weighting with some variations that depend on the data available.

For more information you can check the following introductory texts:

  * Valliant et al (2013) *Practical Tools for Designing and Weighting Survey Samples*. New York: Springer Science+Business Media.
  * Lohr (2009) *Sampling: Design and Analysis*. 2nd Edition. Boston: Books/Cole.
  
And the book accompaining the R 'survey' package:  

  * Lumley (2010) *Complex Surveys: A Guide to Analysis Using R*. New Jersey: John Wiley & Sons Inc.

It is important to note that this guide focuses on surveys based on 'probability sample'.
These are surveys where all units in our statistical population have a chance of being selected
and the probability of selection is known to the researcher. 'Non-probability sample' methods
are diverse, more complex and usually rely on statistical modelling. 

### Basic steps in weighting a survey

Weighting is done to reduce survey bias. Briefly explained, weighting consists on making our sample of survey respondents (more) representative
of our statistical population. By statistical population I mean all those units for which we want to compute estimates.
There are four basic steps in weighting. These are:

1. Base/design weights.
2. Non-response weights.
3. Use of auxiliary data/calibration.
4. Analysis of weight variability/trimming.

The first step consists on computing weights to take into account the differences of units in the probability of being sampled.
'Being sampled' means being selected from the survey frame (i.e. the list of all units) to be approached for a survey response.
This step can be skipped if all units in the survey frame have the same probability of being sampled. This happens, for example
1) when all units in the survey frame are approached for the sample or; 2) when the sampling design corresponds to either 
'simple random sampling without replacement' or 'stratified random sampling with replacement' and the distribution of sampled units across
stratums is proportional to the number of units in each stratum. These are called 'self-weighted' surveys. 

Second, we need to adjust our responses by the differences in probabilities of sampled units to reply to our survey. Our estimates would be biased if some
profile of sampled units had higher propensity to reply than another and these profiles had differences in the dependent variables (i.e. our variables of interest).
In this step, we need to estimate the probability of response using information available for both respondents and non-respondents. Non-response adjustment is not needed
if all sampled units responded to the survey.

The third step consists on adjusting our weights using available information about total population estimates. Note that this is different from the kind of data needed in non-response adjustment (second step). Here we need auxiliary data which tells us information (i.e. estimates such as proportions, means, sums, counts) about the statistical population. The same variables should be available from our respondents but here we don't need information about non-respondents.

The last step is to check the variablity in our computed weights. High variation in weights can lead to some observations having too much importance in our sample. Even if weights reduce bias, they might largely inflate variance of estimates. Therefore, some survey practitioners worry about dealing with highly unequal weights.


## Read data and data management

#### Import data

We first import data into R.

```{r echo=TRUE, warning=FALSE, message=FALSE}

sample.data <- read.spss("data/ESS7SDDFe1_1.sav", to.data.frame = T)  %>%
  filter(cntry == "United Kingdom")

paradata <- read.spss("data/ess7CFe02_1.sav", to.data.frame = T) %>%
  filter(cntry == "United Kingdom") 

responses <- read.spss("data/ESS7e02_1.sav", to.data.frame = T) %>%
  filter(cntry == "United Kingdom") 

```

#### Select variables

Then we select the variables we are going to use in our analysis.

```{r, echo=TRUE, warning=FALSE, message=FALSE}

sample.data %<>%
  select(cntry, idno, psu, domain, stratify, prob)

paradata %<>%
  select(idno, cntry, typesamp, age_su, gndr_su, defectcf, interva, telnum,
         agea_1:agea_4,
         gendera1:gendera4,
         type, access, physa, littera, vandaa, reconva,
         resulb1:resulb80,
         outnic1:outnic80)

responses %<>%
  select(idno, cntry, 
         vote, prtvtbgb,
         prtclbgb, prtdgcl,
         ctzcntr, ctzshipc,
         brncntr,cntrbrthc,
         cgtsmke, cgtsday,
         alcfreq, alcwkdy, alcwknd,
         gndr, agea, edulvlb, edubgb1,
         pdwrk, edctn, uempla, uempli, rtrd)

```




### Merging datafiles

We merge the 'paradata' file containing all sampled units with the 'survey responses' file.
In a real situation, there would also be a 'survey frame' dataset. This would be a third data file
from which the sample was selected. Ideally, the 'survey frame' would include all units from the 
population.

### Filter variables 

We filter the variables that will be used for this example. (we can proably do this directly while importing the data)



## Exploring and presenting the dataset

#### Paradata variables

#### Survey responses

#### Variables of interest

#### Covariates

#### Auxiliary data

## Step 1: Design weights

## Step 2: Non-response weights

## Step 3: Use of auxiliary data

## Step 4: Analysis of weight variability

## Computing an estimate


