---
title: "(Very) basic steps on how to weight a survey sample"
subtitle: "An explained example with R code"
author: "JosepER"
output: html_notebook
---

```{r, echo=TRUE, warning=FALSE, message=FALSE}
library(foreign)
library(magrittr)
library(tidyverse)
options(scipen = 9999)
```


## Introduction

### Note and bibliography 

This is a short guide that shows to weight a survey. Please keep in mind that
there are many different ways of weighting a survey. This guide intends to be a practical document and
intentionally avoids explaining complex or advanced methods. Instead, I aim at providing 
a way of weighting with some variations that depend on the data available.

For more information you can check the following introductory texts:

  * Valliant et al (2013) *Practical Tools for Designing and Weighting Survey Samples*. New York: Springer Science+Business Media.
  * Lohr (2009) *Sampling: Design and Analysis*. 2nd Edition. Boston: Books/Cole.
  
And the book accompaining the R 'survey' package:  

  * Lumley (2010) *Complex Surveys: A Guide to Analysis Using R*. New Jersey: John Wiley & Sons Inc.

It is important to note that this guide focuses on surveys based on 'probability sample'.
These are surveys where all units in our statistical population have a chance of being selected
and the probability of selection is known to the researcher. 'Non-probability sample' methods
are diverse, more complex and usually rely on statistical modelling. 

### Basic steps in weighting a survey

Weighting is done to reduce survey bias. Briefly explained, weighting consists on making our sample of survey respondents (more) representative
of our statistical population. By statistical population I mean all those units for which we want to compute estimates.
There are four basic steps in weighting. These are:

1. Base/design weights.
2. Non-response weights.
3. Use of auxiliary data/calibration.
4. Analysis of weight variability/trimming.

The first step consists on computing weights to take into account the differences of units in the probability of being sampled.
'Being sampled' means being selected from the survey frame (i.e. the list of all units) to be approached for a survey response.
This step can be skipped if all units in the survey frame have the same probability of being sampled. This happens, for example
1) when all units in the survey frame are approached for the sample or; 2) when the sampling design corresponds to either 
'simple random sampling without replacement' or 'stratified random sampling with replacement' and the distribution of sampled units across
stratums is proportional to the number of units in each stratum. These are called 'self-weighted' surveys. 

Second, we need to adjust our responses by the differences in probabilities of sampled units to reply to our survey. Our estimates would be biased if some
profile of sampled units had higher propensity to reply than another and these profiles had differences in the dependent variables (i.e. our variables of interest).
In this step, we need to estimate the probability of response using information available for both respondents and non-respondents. Non-response adjustment is not needed
if all sampled units responded to the survey.

The third step consists on adjusting our weights using available information about total population estimates. Note that this is different from the kind of data needed in non-response adjustment (second step). Here we need auxiliary data which tells us information (i.e. estimates such as proportions, means, sums, counts) about the statistical population. The same variables should be available from our respondents but here we don't need information about non-respondents.

The last step is to check the variablity in our computed weights. High variation in weights can lead to some observations having too much importance in our sample. Even if weights reduce bias, they might largely inflate variance of estimates. Therefore, some survey practitioners worry about dealing with highly unequal weights.


## Read data and data management

#### Import data

We first import data into R.

```{r echo=TRUE, warning=FALSE, message=FALSE}

sample.data <- read.spss("data/ESS7SDDFe1_1.sav", to.data.frame = T)  %>%
  filter(cntry == "United Kingdom")

paradata <- read.spss("data/ess7CFe02_1.sav", to.data.frame = T) %>%
  filter(cntry == "United Kingdom") 

responses <- read.spss("data/ESS7e02_1.sav", to.data.frame = T) %>%
  filter(cntry == "United Kingdom") 

```

#### Select variables

We select the variables we are going to use in our analysis. Here we just
write the names of the variables we intend to use.

```{r, echo=TRUE, warning=FALSE, message=FALSE}

vars.sample.data <- c("idno", "psu", "prob")

# Note: In sample file, domain and stratify variables could be useful for other countries.

vars.paradata <- c("idno", "typesamp", "defectcf","interva", "telnum", 
                   "agea_1", "gendera1", "type", "access", 
                   "physa", "littera", "vandaa", "reconva")

# Note: In paradata file, age of sampled unit could be useful for other countries.    

resp.id <- c("idno")

resp.y <- c("cgtsmke", "cgtsday",
         "alcfreq", "alcwkdy", "alcwknd")

resp.x <- c("vote", "prtvtbgb",
            "prtclbgb", "prtdgcl",
            "ctzcntr", "ctzshipc",
         "brncntr","cntbrthc",
         "gndr", "agea", "eisced",
         "pdwrk", "edctn", "uempla", "uempli", "rtrd")

```

Then we keep the variable labels (although these are not common in R).

```{r, echo=TRUE, warning=FALSE, message=FALSE}

selected.labels.sample.data <- attributes(sample.data)$variable.labels[which(names(sample.data) %in% vars.sample.data)]

selected.labels.paradata <- attributes(paradata)$variable.labels[which(names(paradata) %in% vars.paradata)]

selected.labels.responses <- attributes(responses)$variable.labels[which(names(responses) %in% c(resp.id, resp.y, resp.x))] 

attributes(responses)$variable.labels %>% 
  cbind(names(responses),.) %>% 
  as_data_frame %>% 
  write_csv("interim_output/variable_labels.csv")

```

Now we do the selection of variables from the three data sets. 

```{r, echo=TRUE, warning=FALSE, message=FALSE}

sample.data %<>% 
  .[vars.sample.data]

paradata %<>%
  .[vars.paradata]

responses %<>%
  .[which(names(responses) %in% c(resp.id, resp.y, resp.x))]

```


### Merging datafiles

We merge the 'paradata' file containing all sampled units with the 'survey responses' file.
In a real situation, there would also be a 'survey frame' dataset. This would be a third data file
from which the sample was selected. Ideally, the 'survey frame' would include all units from the 
population.

```{r, echo=TRUE, warning=FALSE, message=FALSE}

data <- paradata %>%
  left_join(sample.data, by = "idno") %>%
  left_join(responses, by = "idno") %>%
  arrange(interva)

rm(paradata,
   sample.data,
   responses)

```

And we add the labels we kept before.

```{r, echo=TRUE, warning=FALSE, message=FALSE}

# Note: There are other variables that could be selected from paradata (i.e. result of visits, refusals, etc.)

attributes(data)$variable.labels <- c(selected.labels.paradata, selected.labels.sample.data,
                                      selected.labels.responses)
```


### Recoding

Recoding daily cigarette consumption. All those that responded that don't smoke should have a 0.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
data$cgtsday[data$cgtsmke %in% c("I have never smoked",
                                 "I don't smoke now but I used to",
                                 "I have only smoked a few times")] <- 0

data$alcohol_day <- NA 
data$alcohol_day <- (data$alcwkdy * 5 + data$alcwknd *2)/7 

data$alcohol_day[which(data$alcfreq == "Several times a week")] <- data$alcohol_day / 2.5
data$alcohol_day[which(data$alcfreq == "Once a week")] <- data$alcohol_day/7
data$alcohol_day[which(data$alcfreq == "2-3 times a month")] <- data$alcohol_day/10
data$alcohol_day[which(data$alcfreq == "Once a month")] <- data$alcohol_day/30
data$alcohol_day[which(data$alcfreq == "Less than once a month")] <- data$alcohol_day/50
data$alcohol_day[which(data$alcfreq == "Never")] <- 0

resp.y <- c(resp.y, "alcohol_day")
```


## Exploring and presenting the dataset

The merged data set contains sampled *respondents and non-respondents*. It contains a total of `r dim(data)[[1]]` units and `r dim(data)[[2]]` variables.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
dim(data)
```

This is how the dataset looks like:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
head(data, 10)
```

And this is a list of the variables it contains (with their labels). 

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cbind(names(data),attributes(data)$variable.labels) %>% 
  as_data_frame() %>%
  print()
```

Here I will try to give population estimates for cigarette and alcohol consumption in the UK. These will be our 'y' variables. The idea is to first give descriptives of the distribution of these two variables such as quantiles and mean. Then I will do a simple extrapolation and compute total cigarette and alcohol consumption for the whole UK.

These are our y variables:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
data[resp.y]
```

*cgtsday* and *alcohol_day* measure the average number of cigarettes and grams of alcohol consumed per day. *Alcohol_day* was computed in the *Recoding* section.

#### Paradata variables

Our survey also has variables 


#### Survey responses

#### Variables of interest

#### Covariates

#### Auxiliary data

## Step 1: Design weights

## Step 2: Non-response weights

## Step 3: Use of auxiliary data

## Step 4: Analysis of weight variability

## Computing an estimate


